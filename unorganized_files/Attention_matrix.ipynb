{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e4480bf-e75a-44dd-91d5-31fbccd75d6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T12:55:16.492161Z",
     "iopub.status.busy": "2025-05-11T12:55:16.491636Z",
     "iopub.status.idle": "2025-05-11T12:55:17.883466Z",
     "shell.execute_reply": "2025-05-11T12:55:17.882898Z",
     "shell.execute_reply.started": "2025-05-11T12:55:16.492142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/conda/lib/python3.12/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/conda/lib/python3.12/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/conda/lib/python3.12/site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn\n",
    "import torch\n",
    "\n",
    "def compute_channel_mean_std(tensor, channel_indices):\n",
    "    \"\"\"Compute mean and std per channel for specified indices.\"\"\"\n",
    "    means = []\n",
    "    stds = []\n",
    "    for idx in channel_indices:\n",
    "        data = tensor[:, idx, :]\n",
    "        means.append(data.mean())\n",
    "        stds.append(data.std())\n",
    "    return torch.stack(means), torch.stack(stds)\n",
    "\n",
    "def apply_z_score_normalization(tensor, channel_indices, means, stds):\n",
    "    \"\"\"Apply Z-score normalization using precomputed means and stds.\"\"\"\n",
    "    tensor = tensor.clone()\n",
    "    for i, idx in enumerate(channel_indices):\n",
    "        mean = means[i]\n",
    "        std = stds[i]\n",
    "        if std == 0:\n",
    "            std = 1.0\n",
    "        tensor[:, idx, :] = (tensor[:, idx, :] - mean) / std\n",
    "    return tensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_normalized_heatmap(X, sample_idx=0, channels=range(18)):\n",
    "    \"\"\"\n",
    "    Plot a heatmap of selected channels for a given sample from the normalized tensor.\n",
    "\n",
    "    Args:\n",
    "        X (torch.Tensor): Normalized input tensor of shape [N, 18, 23].\n",
    "        sample_idx (int): Index of the sample to visualize.\n",
    "        channels (list or range): Which channels to plot (default: first 10 continuous channels).\n",
    "\n",
    "    \"\"\"\n",
    "    # Safety checks\n",
    "    if not isinstance(X, torch.Tensor):\n",
    "        raise ValueError(\"Input X must be a torch.Tensor.\")\n",
    "    \n",
    "    if sample_idx < 0 or sample_idx >= X.shape[0]:\n",
    "        raise IndexError(f\"Sample index {sample_idx} out of range. Total samples: {X.shape[0]}\")\n",
    "    \n",
    "    sample = X[sample_idx, channels, :]  # [len(channels), 23]\n",
    "    \n",
    "    # Detach if needed\n",
    "    if sample.requires_grad:\n",
    "        sample = sample.detach()\n",
    "    \n",
    "    # Move to CPU if needed\n",
    "    if sample.is_cuda:\n",
    "        sample = sample.cpu()\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(sample.numpy(), aspect='auto', interpolation='nearest')\n",
    "    plt.colorbar(label='Z-score normalized signal')\n",
    "    plt.title(f'Heatmap of Sample {sample_idx} (Channels {channels.start}-{channels.stop-1})')\n",
    "    plt.xlabel('Sequence Position (0 → 22)')\n",
    "    plt.ylabel('Channel')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bf45ef6-143c-471d-b353-aeb4db85326b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T14:09:34.701624Z",
     "iopub.status.busy": "2025-05-11T14:09:34.701287Z",
     "iopub.status.idle": "2025-05-11T14:09:39.238993Z",
     "shell.execute_reply": "2025-05-11T14:09:39.238418Z",
     "shell.execute_reply.started": "2025-05-11T14:09:34.701606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 每层注意力图已保存并标注：\n",
      "  - attention_maps/positive_layers/layer_1.png … layer_3.png\n",
      "  - attention_maps/negative_layers/layer_1.png … layer_3.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------------------\n",
    "# 1) 模型定义（同之前）\n",
    "# ----------------------------\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, seq_length,\n",
    "                 hidden_dim=256, num_layers=3,\n",
    "                 nhead=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        self.positional_encoding = nn.Parameter(\n",
    "            torch.zeros(1, seq_length, hidden_dim))\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_dim, nhead=nhead,\n",
    "            dim_feedforward=hidden_dim*2,\n",
    "            dropout=dropout, activation='relu')\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer, num_layers=num_layers)\n",
    "        self.layernorm = nn.LayerNorm(hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, channels=18, seq=23]\n",
    "        x = x.transpose(1, 2)                    # → [B, seq, 18]\n",
    "        x = self.embedding(x) + self.positional_encoding\n",
    "        x = self.layernorm(x)\n",
    "        x = x.transpose(0, 1)                    # → [seq, B, hidden]\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.transpose(0, 1).mean(dim=1)        # → [B, hidden]\n",
    "        return self.sigmoid(self.fc(x)).squeeze()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2) 载入 & 随机抽 300 个\n",
    "# ----------------------------\n",
    "positives = torch.load('Positive.pt').float()\n",
    "negatives = torch.load('Negative.pt').float()\n",
    "num_samples = 300\n",
    "\n",
    "if positives.size(0) > num_samples:\n",
    "    positives = positives[torch.randperm(positives.size(0))[:num_samples]]\n",
    "if negatives.size(0) > num_samples:\n",
    "    negatives = negatives[torch.randperm(negatives.size(0))[:num_samples]]\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3) 加载模型权重\n",
    "# ----------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = TransformerClassifier(input_dim=18, seq_length=23).to(device)\n",
    "ckpt = torch.load('best_model_1th.pth', map_location=device)\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 4) 计算平均注意力（batch_size=1024）\n",
    "# ----------------------------\n",
    "def compute_avg_attn(X, model, batch_size=1024):\n",
    "    accum = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, X.size(0), batch_size):\n",
    "            batch = X[i:i+batch_size].to(device)      # [B,18,23]\n",
    "            x = batch.transpose(1, 2)                 # [B,23,18]\n",
    "            x = model.embedding(x) + model.positional_encoding\n",
    "            x = model.layernorm(x)\n",
    "            x = x.transpose(0, 1)                     # [23,B,hidden]\n",
    "\n",
    "            for L, layer in enumerate(model.transformer_encoder.layers):\n",
    "                attn_out, attn_w = layer.self_attn(\n",
    "                    x, x, x,\n",
    "                    need_weights=True,\n",
    "                    average_attn_weights=False,\n",
    "                    attn_mask=None,\n",
    "                    key_padding_mask=None,\n",
    "                    is_causal=False\n",
    "                )\n",
    "                # attn_w: [B, heads, seq, seq]\n",
    "                accum[L].append(attn_w.cpu())\n",
    "\n",
    "                x = layer.norm1(x + layer.dropout1(attn_out))\n",
    "                ff = layer.linear2(\n",
    "                    layer.dropout(layer.activation(\n",
    "                        layer.linear1(x))))\n",
    "                x = layer.norm2(x + layer.dropout2(ff))\n",
    "\n",
    "    avg = {}\n",
    "    for L, mats in accum.items():\n",
    "        all_w = torch.cat(mats, dim=0)           # [total_samples, heads, seq, seq]\n",
    "        avg[L] = all_w.mean(0).numpy()           # [heads, seq, seq]\n",
    "    return avg\n",
    "\n",
    "avg_pos = compute_avg_attn(positives, model)\n",
    "avg_neg = compute_avg_attn(negatives, model)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 5) 按层保存子图，标题写全 Layer，并标注 Query/Key 位置\n",
    "# ----------------------------\n",
    "def save_per_layer_with_labels(avg_attn, out_dir):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    seq_len = next(iter(avg_attn.values())).shape[1]\n",
    "    # 设置少量刻度以免拥挤\n",
    "    ticks = list(range(0, seq_len, 5))\n",
    "    if seq_len - 1 not in ticks:\n",
    "        ticks.append(seq_len - 1)\n",
    "\n",
    "    n_heads = next(iter(avg_attn.values())).shape[0]\n",
    "\n",
    "    for layer_idx, mats in avg_attn.items():\n",
    "        fig, axes = plt.subplots(\n",
    "            1, n_heads,\n",
    "            figsize=(n_heads * 1.5, 2),\n",
    "            squeeze=False\n",
    "        )\n",
    "        for h in range(n_heads):\n",
    "            ax = axes[0][h]\n",
    "            ax.imshow(mats[h], aspect='auto')\n",
    "            ax.set_xticks(ticks)\n",
    "            ax.set_xticklabels(ticks, fontsize=4)\n",
    "            ax.set_xlabel('Key position', fontsize=6)\n",
    "            ax.set_yticks(ticks)\n",
    "            ax.set_yticklabels(ticks, fontsize=4)\n",
    "            ax.set_ylabel('Query position', fontsize=6)\n",
    "            # Title includes full \"Layer\" name\n",
    "            ax.set_title(f'Layer {layer_idx+1} - Head {h+1}', fontsize=6)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{out_dir}/layer_{layer_idx+1}.png\", dpi=300)\n",
    "        plt.close(fig)\n",
    "\n",
    "# 分别保存正负样本\n",
    "save_per_layer_with_labels(avg_pos, 'attention_maps/positive_layers')\n",
    "save_per_layer_with_labels(avg_neg, 'attention_maps/negative_layers')\n",
    "\n",
    "print(\"✅ 每层注意力图已保存并标注：\")\n",
    "print(\"  - attention_maps/positive_layers/layer_1.png … layer_3.png\")\n",
    "print(\"  - attention_maps/negative_layers/layer_1.png … layer_3.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272d92cf-0088-49e0-a866-cda6d5d50cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
